"""
Enhanced Vulnerability Analysis Phase - Integrated with Web Enumeration
Combines service vulnerabilities with web-specific findings
"""
import os
import json
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

from services.utils.cve_lookup import cve_db
from services.ai.knowledge_manager import get_knowledge_manager
from services.exploit_search import ExploitSearchManager
from services.poc_execution import PoCExecutor, ResultValidator
from services.utils.output_manager import get_output_manager
from models import Phase, Job

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)


class EnhancedVulnerabilityAnalyzer:
    """
    Enhanced vulnerability analyzer that integrates:
    1. Service-level vulnerabilities (from nmap)
    2. Web application vulnerabilities (from path analysis)
    3. Exploit search and matching
    4. PoC execution and validation
    5. Attack correlation and prioritization
    """

    def __init__(self):
        self.knowledge_manager = get_knowledge_manager()

        # Initialize exploit search manager with API keys from environment
        self.search_manager = ExploitSearchManager(
            github_token=os.getenv('GITHUB_TOKEN'),
            google_api_key=os.getenv('GOOGLE_API_KEY'),
            google_search_engine_id=os.getenv('GOOGLE_SEARCH_ENGINE_ID'),
            exploitdb_path=os.getenv('EXPLOITDB_PATH', '/usr/share/exploitdb')
        )

        self.poc_executor = PoCExecutor()
        self.result_validator = ResultValidator()

        # Log API availability
        stats = self.search_manager.get_statistics()
        logger.info("EnhancedVulnerabilityAnalyzer initialized")
        logger.info(f"  GitHub API: {'Authenticated' if stats['github_authenticated'] else 'Anonymous (rate limited)'}")
        logger.info(f"  ExploitDB: {'Available' if stats['exploitdb_available'] else 'Not available'}")
        logger.info(f"  Google API: {'Available' if stats['google_api_available'] else 'Not configured'}")

    def analyze_service(
        self,
        target: str,
        service: str,
        version: str,
        port: int,
        os_hint: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Comprehensive vulnerability analysis for a service.

        Args:
            target: Target IP/hostname
            service: Service name
            version: Version string
            port: Service port
            os_hint: OS hint from nmap

        Returns:
            Service analysis results
        """
        analysis = {
            'service': service,
            'version': version,
            'port': port,
            'target': target,
            'os_hint': os_hint,
            'cves_found': [],
            'exploits_from_kb': [],
            'exploits_from_search': [],
            'poc_results': [],
            'successful_exploits': [],
            'risk_level': 'unknown'
        }

        logger.info(f"Analyzing {service} {version} on {target}:{port}")

        try:
            # Step 1: Find CVEs
            cves = cve_db.lookup_service_vulnerabilities(service, version)
            analysis['cves_found'] = cves
            logger.info(f"  Found {len(cves)} CVEs")

            # Step 2: Find matching exploits from knowledge base
            kb_exploits = self.knowledge_manager.find_matching_exploits(
                service=service,
                version=version,
                os=os_hint or "",
                n_results=10
            )
            analysis['exploits_from_kb'] = kb_exploits
            logger.info(f"  Found {len(kb_exploits)} exploits from knowledge base")

            # Step 3: Search online for exploits
            online_exploits = []

            # Search by CVE
            for cve in cves[:3]:
                cve_id = cve.get('cve_id')
                if cve_id:
                    results = self.search_manager.search_for_cve(cve_id, max_results=5)
                    online_exploits.extend(results)

            # Search by service
            service_exploits = self.search_manager.search_for_service(
                service=service,
                version=version,
                os=os_hint,
                max_results=10
            )
            online_exploits.extend(service_exploits)

            analysis['exploits_from_search'] = online_exploits
            logger.info(f"  Found {len(online_exploits)} exploits from online search")

            # Step 4: Determine risk level
            analysis['risk_level'] = self._calculate_service_risk(analysis)

        except Exception as e:
            logger.error(f"Error analyzing service: {e}", exc_info=True)
            analysis['error'] = str(e)

        return analysis

    def analyze_web_vulnerabilities(
        self,
        target: str,
        web_enumeration_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Analyze web-specific vulnerabilities from enumeration data.

        Args:
            target: Target hostname
            web_enumeration_data: Results from web enumeration phase

        Returns:
            Web vulnerability analysis
        """
        logger.info(f"Analyzing web vulnerabilities for {target}")

        analysis = {
            'target': target,
            'web_vulnerabilities': [],
            'path_vulnerabilities': [],
            'auth_vulnerabilities': [],
            'config_vulnerabilities': [],
            'risk_summary': {
                'critical': 0,
                'high': 0,
                'medium': 0,
                'low': 0
            }
        }

        try:
            # Extract path analysis results
            path_analysis = web_enumeration_data.get('path_analysis', {}).get('analysis', {})
            findings = path_analysis.get('findings', [])

            # Categorize vulnerabilities
            for finding in findings:
                vuln = {
                    'path': finding.get('path'),
                    'risk': finding.get('risk', 'low'),
                    'category': finding.get('category'),
                    'description': finding.get('description'),
                    'attack_type': finding.get('attack_type'),
                    'testing_method': finding.get('testing_method')
                }

                # Add to appropriate category
                category = finding.get('category', '').lower()
                if 'authentication' in category or 'auth' in category:
                    analysis['auth_vulnerabilities'].append(vuln)
                elif 'config' in category or 'sensitive' in category:
                    analysis['config_vulnerabilities'].append(vuln)
                else:
                    analysis['path_vulnerabilities'].append(vuln)

                # Update risk summary
                risk = finding.get('risk', 'low')
                if risk in analysis['risk_summary']:
                    analysis['risk_summary'][risk] += 1

            # Extract authentication analysis
            auth_analysis = web_enumeration_data.get('authentication_analysis', {})
            if auth_analysis.get('vulnerable', 0) > 0:
                for result in auth_analysis.get('results', []):
                    if result.get('enumeration_possible'):
                        analysis['auth_vulnerabilities'].append({
                            'path': result.get('url'),
                            'risk': 'low',
                            'category': 'Username Enumeration',
                            'description': 'Login page vulnerable to username enumeration',
                            'attack_type': 'Authentication Bypass',
                            'evidence': result.get('evidence', [])
                        })
                        analysis['risk_summary']['low'] += 1

            # Extract security header issues
            fingerprints = web_enumeration_data.get('server_fingerprints', [])
            for fp in fingerprints:
                missing_headers = fp.get('missing_security_headers', [])
                for header in missing_headers:
                    if header.get('risk', '').lower() in ['critical', 'high']:
                        analysis['config_vulnerabilities'].append({
                            'path': fp.get('url'),
                            'risk': header.get('risk', 'low').lower(),
                            'category': 'Missing Security Header',
                            'description': f"Missing {header.get('header')}: {header.get('description')}",
                            'header': header.get('header')
                        })

                        risk_level = header.get('risk', 'low').lower()
                        if risk_level in analysis['risk_summary']:
                            analysis['risk_summary'][risk_level] += 1

            # Aggregate all vulnerabilities
            analysis['web_vulnerabilities'] = (
                analysis['path_vulnerabilities'] +
                analysis['auth_vulnerabilities'] +
                analysis['config_vulnerabilities']
            )

            logger.info(f"  Web vulnerabilities found: {len(analysis['web_vulnerabilities'])}")
            logger.info(f"  Critical: {analysis['risk_summary']['critical']}, "
                       f"High: {analysis['risk_summary']['high']}, "
                       f"Medium: {analysis['risk_summary']['medium']}")

        except Exception as e:
            logger.error(f"Error analyzing web vulnerabilities: {e}", exc_info=True)
            analysis['error'] = str(e)

        return analysis

    def correlate_vulnerabilities(
        self,
        service_analysis: List[Dict[str, Any]],
        web_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Correlate service and web vulnerabilities to identify attack chains.

        Args:
            service_analysis: Results from service analysis
            web_analysis: Results from web vulnerability analysis

        Returns:
            Correlation results with attack chains
        """
        logger.info("Correlating service and web vulnerabilities...")

        correlation = {
            'attack_chains': [],
            'high_priority_targets': [],
            'exploit_recommendations': []
        }

        try:
            # Identify high-value targets (critical + high severity)
            for service in service_analysis:
                if service.get('risk_level') in ['critical', 'high']:
                    correlation['high_priority_targets'].append({
                        'type': 'service',
                        'service': service.get('service'),
                        'port': service.get('port'),
                        'risk': service.get('risk_level'),
                        'exploits_available': len(service.get('exploits_from_kb', []))
                    })

            # Add web vulnerabilities
            for vuln in web_analysis.get('web_vulnerabilities', []):
                if vuln.get('risk') in ['critical', 'high']:
                    correlation['high_priority_targets'].append({
                        'type': 'web',
                        'path': vuln.get('path'),
                        'category': vuln.get('category'),
                        'risk': vuln.get('risk'),
                        'attack_type': vuln.get('attack_type')
                    })

            # Identify potential attack chains
            # Example: Exposed admin panel + service with RCE
            for service in service_analysis:
                has_rce = any(
                    exp.get('exploit_type') == 'rce'
                    for exp in service.get('exploits_from_kb', [])
                )

                if has_rce:
                    # Check for exposed admin panels
                    admin_panels = [
                        v for v in web_analysis.get('path_vulnerabilities', [])
                        if 'admin' in v.get('category', '').lower()
                    ]

                    if admin_panels:
                        correlation['attack_chains'].append({
                            'chain_type': 'Admin Panel + RCE',
                            'description': f"Exposed admin panel with RCE in {service.get('service')}",
                            'steps': [
                                f"1. Access admin panel: {admin_panels[0].get('path')}",
                                f"2. Exploit RCE in {service.get('service')} {service.get('version')}",
                                "3. Gain shell access"
                            ],
                            'risk': 'critical'
                        })

            # Generate exploit recommendations
            for target in correlation['high_priority_targets'][:10]:
                if target['type'] == 'service':
                    correlation['exploit_recommendations'].append({
                        'target': f"{target['service']} on port {target['port']}",
                        'recommendation': 'Execute service-level exploits with PoC testing',
                        'priority': 'high' if target['risk'] == 'critical' else 'medium'
                    })
                elif target['type'] == 'web':
                    correlation['exploit_recommendations'].append({
                        'target': target['path'],
                        'recommendation': f"Test {target['attack_type']} vulnerability",
                        'priority': 'high' if target['risk'] == 'critical' else 'medium'
                    })

        except Exception as e:
            logger.error(f"Error correlating vulnerabilities: {e}", exc_info=True)
            correlation['error'] = str(e)

        return correlation

    def _calculate_service_risk(self, analysis: Dict[str, Any]) -> str:
        """Calculate risk level for a service."""
        cves = analysis.get('cves_found', [])
        exploits_kb = analysis.get('exploits_from_kb', [])
        exploits_online = analysis.get('exploits_from_search', [])

        # Check for critical CVEs
        critical_cves = [c for c in cves if c.get('severity', '').lower() == 'critical']
        high_cves = [c for c in cves if c.get('severity', '').lower() == 'high']

        # Check for exploits with high success rate
        proven_exploits = [
            e for e in exploits_kb
            if e.get('success_count', 0) > 0
        ]

        # Determine risk
        if critical_cves and (proven_exploits or len(exploits_online) > 0):
            return 'critical'
        elif high_cves and len(exploits_kb) > 0:
            return 'high'
        elif len(cves) > 0 and (len(exploits_kb) > 0 or len(exploits_online) > 0):
            return 'medium'
        elif len(cves) > 0:
            return 'low'
        # NEW: Flag as vulnerable if exploits exist even without CVEs
        elif len(exploits_online) > 0 or len(exploits_kb) > 0:
            return 'medium'
        else:
            return 'info'

    def create_exploit_based_vulnerabilities(
        self,
        service_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Convert exploit search results into formal vulnerability findings.
        These are flagged as A06:2021 - Vulnerable and Outdated Components.

        Args:
            service_results: List of service analysis results

        Returns:
            List of vulnerability dictionaries for report generation
        """
        vulnerability_results = []

        logger.info(f"[create_exploit_based_vulnerabilities] Processing {len(service_results)} service results")

        for service_analysis in service_results:
            service = service_analysis.get('service', 'Unknown')
            version = service_analysis.get('version', '')
            port = service_analysis.get('port', 'N/A')
            risk_level = service_analysis.get('risk_level', 'info')

            # Skip services with no exploits found
            exploits_online = service_analysis.get('exploits_from_search', [])
            exploits_kb = service_analysis.get('exploits_from_kb', [])
            cves_found = service_analysis.get('cves_found', [])

            all_exploits = exploits_online + exploits_kb

            logger.info(f"[create_exploit_based_vulnerabilities] Service: {service} {version} on port {port}")
            logger.info(f"  - CVEs found: {len(cves_found)}")
            logger.info(f"  - Exploits online: {len(exploits_online)}")
            logger.info(f"  - Exploits KB: {len(exploits_kb)}")

            if not all_exploits and not cves_found:
                logger.info(f"  - Skipping (no exploits or CVEs)")
                continue

            # Create vulnerabilities list for this service
            vulnerabilities = []

            # Add CVE-based vulnerabilities
            for cve in cves_found:
                vulnerabilities.append({
                    'cve_id': cve.get('cve_id', 'N/A'),
                    'severity': cve.get('severity', 'Medium'),
                    'description': cve.get('description', f"Known vulnerability in {service} {version}"),
                    'mitigation': cve.get('mitigation', f"Update {service} to the latest patched version"),
                    'type': 'cve'
                })

            # Add exploit-based vulnerability if exploits found but no CVEs
            # or if exploits provide additional attack vectors
            if all_exploits:
                # Determine severity based on exploit types
                has_rce = any(
                    'rce' in str(e.get('exploit_type', '')).lower() or
                    'remote' in str(e.get('title', '')).lower()
                    for e in all_exploits
                )
                has_dos = any(
                    'dos' in str(e.get('exploit_type', '')).lower() or
                    'denial' in str(e.get('title', '')).lower()
                    for e in all_exploits
                )

                if has_rce:
                    exploit_severity = 'Critical'
                elif has_dos:
                    exploit_severity = 'High'
                else:
                    exploit_severity = 'High'

                # Build exploit evidence
                exploit_evidence = []
                for exploit in all_exploits[:5]:  # Top 5 exploits
                    source = exploit.get('source', 'Unknown')
                    title = exploit.get('title', exploit.get('name', 'Unknown exploit'))
                    url = exploit.get('url', exploit.get('html_url', ''))
                    edb_id = exploit.get('edb_id', '')

                    evidence_item = {
                        'source': source,
                        'title': title,
                        'url': url,
                        'edb_id': edb_id,
                        'exploit_type': exploit.get('exploit_type', 'unknown')
                    }
                    exploit_evidence.append(evidence_item)

                # Create the exploit-based vulnerability finding
                vulnerabilities.append({
                    'cve_id': 'N/A',
                    'severity': exploit_severity,
                    'description': f"Public exploits available for {service} {version}. "
                                   f"Found {len(all_exploits)} exploit(s) from ExploitDB, GitHub, and other sources. "
                                   f"This indicates the service version has known security weaknesses that can be exploited.",
                    'mitigation': f"Immediately update {service} to the latest stable version. "
                                  f"Review vendor security advisories and apply all available patches. "
                                  f"Consider implementing additional security controls such as WAF or IPS.",
                    'type': 'exploit_available',
                    'exploit_count': len(all_exploits),
                    'exploit_evidence': exploit_evidence,
                    'owasp_category': 'A06:2021 â€“ Vulnerable and Outdated Components'
                })

            # Add to results if any vulnerabilities found
            if vulnerabilities:
                vulnerability_results.append({
                    'service': service,
                    'version': version,
                    'port': port,
                    'risk_level': risk_level,
                    'vulnerabilities': vulnerabilities
                })
                logger.info(f"  - Added {len(vulnerabilities)} vulnerabilities for {service} {version}")

        logger.info(f"[create_exploit_based_vulnerabilities] Total: {len(vulnerability_results)} services with vulnerabilities")
        total_vulns = sum(len(vr.get('vulnerabilities', [])) for vr in vulnerability_results)
        logger.info(f"[create_exploit_based_vulnerabilities] Total vulnerability entries: {total_vulns}")

        return vulnerability_results


def run_vulnerability_analysis_phase_enhanced(
    db_session,
    job: Job,
    info_gathering_data: Dict[str, Any],
    web_enumeration_data: Optional[Dict[str, Any]] = None
) -> Optional[Phase]:
    """
    Run enhanced vulnerability analysis with web integration.

    Args:
        db_session: Database session
        job: Current job
        info_gathering_data: Information gathering results
        web_enumeration_data: Web enumeration results (optional)

    Returns:
        Phase object with results
    """
    logger.info("="*80)
    logger.info(f"[Job {job.id}] STARTING ENHANCED VULNERABILITY ANALYSIS")
    logger.info("="*80)

    phase = Phase(
        job_id=job.id,
        phase_name="Vulnerability Analysis",
        data={},
        log_path=None,
        status="ongoing",
    )
    db_session.add(phase)
    db_session.commit()
    db_session.refresh(phase)

    try:
        analyzer = EnhancedVulnerabilityAnalyzer()

        # Part 1: Service-Level Analysis
        logger.info(f"[Job {job.id}] === PART 1: Service Vulnerability Analysis ===")

        nmap_data = info_gathering_data.get('nmap', {})
        parsed_ports = nmap_data.get('parsed_ports', [])
        os_info = nmap_data.get('os_info', {})
        os_hint = os_info.get('os', '')

        service_results = []
        total_service_cves = 0
        total_service_exploits = 0

        logger.info(f"[Job {job.id}] Found {len(parsed_ports)} ports from nmap")

        for port_info in parsed_ports:
            if port_info.get('state') != 'open':
                continue

            service_name = port_info.get('service', 'unknown')
            version = port_info.get('version', '')
            port = port_info.get('port')

            logger.info(f"[Job {job.id}] Port {port}: {service_name} version='{version}'")

            if service_name == 'unknown' or not version:
                logger.info(f"[Job {job.id}]   -> Skipping (service={service_name}, version='{version}')")
                continue

            logger.info(f"[Job {job.id}]   -> Analyzing service...")

            service_analysis = analyzer.analyze_service(
                target=job.target,
                service=service_name,
                version=version,
                port=port,
                os_hint=os_hint
            )

            service_results.append(service_analysis)
            total_service_cves += len(service_analysis['cves_found'])
            total_service_exploits += (
                len(service_analysis['exploits_from_kb']) +
                len(service_analysis['exploits_from_search'])
            )

        logger.info(f"[Job {job.id}] Service analysis: {total_service_cves} CVEs, {total_service_exploits} exploits")

        # Part 1.5: Convert exploit findings into vulnerability results for reporting
        logger.info(f"[Job {job.id}] === PART 1.5: Creating Vulnerability Results from Exploits ===")
        vulnerability_results = analyzer.create_exploit_based_vulnerabilities(service_results)
        total_vuln_findings = sum(len(vr.get('vulnerabilities', [])) for vr in vulnerability_results)
        logger.info(f"[Job {job.id}] Created {total_vuln_findings} vulnerability findings from {len(vulnerability_results)} services")

        # Part 2: Web Vulnerability Analysis
        logger.info(f"[Job {job.id}] === PART 2: Web Vulnerability Analysis ===")

        web_results = None
        if web_enumeration_data:
            web_results = analyzer.analyze_web_vulnerabilities(
                target=job.target,
                web_enumeration_data=web_enumeration_data
            )

            logger.info(f"[Job {job.id}] Web analysis: {len(web_results['web_vulnerabilities'])} vulnerabilities")
        else:
            logger.warning(f"[Job {job.id}] No web enumeration data available")

        # Part 3: Vulnerability Correlation
        logger.info(f"[Job {job.id}] === PART 3: Vulnerability Correlation ===")

        correlation = None
        if web_results:
            correlation = analyzer.correlate_vulnerabilities(
                service_analysis=service_results,
                web_analysis=web_results
            )

            logger.info(f"[Job {job.id}] Identified {len(correlation['attack_chains'])} attack chains")
            logger.info(f"[Job {job.id}] High-priority targets: {len(correlation['high_priority_targets'])}")

        # Compile results
        results = {
            'target': job.target,
            'analysis_version': 'enhanced_v2',
            'timestamp': datetime.now().isoformat(),

            # Service analysis
            'service_analysis': {
                'total_services': len(service_results),
                'total_cves': total_service_cves,
                'total_exploits': total_service_exploits,
                'services': service_results
            },

            # Vulnerability results for report generation (CVEs + exploit-based findings)
            'vulnerability_results': vulnerability_results,

            # Web analysis
            'web_analysis': web_results,

            # Correlation
            'correlation': correlation,

            # Summary
            'summary': {
                'total_vulnerabilities': total_vuln_findings + (len(web_results['web_vulnerabilities']) if web_results else 0),
                'critical_findings': (
                    sum(1 for s in service_results if s.get('risk_level') == 'critical') +
                    (web_results['risk_summary']['critical'] if web_results else 0)
                ),
                'high_findings': (
                    sum(1 for s in service_results if s.get('risk_level') == 'high') +
                    (web_results['risk_summary']['high'] if web_results else 0)
                ),
                'attack_chains': len(correlation['attack_chains']) if correlation else 0,
                'services_with_exploits': len([vr for vr in vulnerability_results if any(v.get('type') == 'exploit_available' for v in vr.get('vulnerabilities', []))])
            }
        }

        # Save outputs using OutputManager
        try:
            output_manager = get_output_manager(job.id)
            vuln_data_path = output_manager.save_vulnerability_analysis(results)
            logger.info(f"[Job {job.id}] Saved vulnerability analysis to {vuln_data_path}")
        except Exception as e:
            logger.warning(f"[Job {job.id}] Failed to save vulnerability outputs: {e}")

        phase.data = results
        phase.status = "success"
        phase.updated_at = datetime.now()
        db_session.commit()

        logger.info("="*80)
        logger.info(f"[Job {job.id}] VULNERABILITY ANALYSIS COMPLETED")
        logger.info(f"[Job {job.id}] Total vulnerabilities: {results['summary']['total_vulnerabilities']}")
        logger.info(f"[Job {job.id}] Critical: {results['summary']['critical_findings']}")
        logger.info(f"[Job {job.id}] High: {results['summary']['high_findings']}")
        logger.info("="*80)

        return phase

    except Exception as e:
        import traceback
        logger.error(f"[Job {job.id}] Enhanced vulnerability analysis failed: {e}", exc_info=True)

        phase.data = {
            "error": str(e),
            "traceback": traceback.format_exc()
        }
        phase.status = "failed"
        phase.updated_at = datetime.now()
        db_session.commit()

        return phase

    finally:
        try:
            analyzer.poc_executor.cleanup_workspace()
        except:
            pass
